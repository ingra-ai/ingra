---
title: Introduction to Ingra - Functions as a Service (FaaS)
description: Learn how Ingra, a Functions as a Service (FaaS) platform, integrates with Large Language Models (LLMs) to enable unlimited function tool calling and seamless automation.
---
# Introduction

Ingra is a highly extensible platform designed as a Functions as a Service (FaaS) to integrate with various Large Language Models (LLMs). Ingra enables LLMs to have unlimited function tool calling and the ability to create functions when they are not present. The platform aims to democratize AI, allowing users to quickly prototype, automate workflows, and integrate diverse services through seamless function execution.

## How Ingra Works

Ingra hosts functions that you own or subscribed to, as an API which can be accessed by GPTs via [openapi.json]({CONST.HUBS_OPENAPI_URL})

All the functions that is accessible to user can also be viewed at the following [Swagger]({CONST.HUBS_SWAGGER_URL})

## Core Features

Ingra offers a suite of powerful features, summarized as follows:
- **Functions Hub**: Discover, curate, and manage a diverse set of functions. Supports self-function generation tailored to user needs, empowering LLMs to call and create functions dynamically.

- **OpenAPI and Swagger Specs**: Auto-generated specs for curated functions, simplifying integration with external services.
- **VM Execution**: Secure virtual machine environment for safe and isolated function execution.
- **Privacy Controls**: Granular privacy settings to manage data access and interactions with AI.
- **Function Marketplace**: Community-driven space to share and customize functions, fostering collaboration in AI tool creation.

- **ChatGPT Plugin Integration**: Conversational interface to interact with functions through natural language commands, highlighting the FaaS capabilities of Ingra.
